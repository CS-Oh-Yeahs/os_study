# os_study 
# 🗳️ Virtual Memory

> 물리적 메모리의 주소변환은 운영체제가 관여하지 않지만 Virtual Memory 기법은 운영체제가 관여한다.
> 

## 1. Demand Paging

> 실제로 사용자 프로그램에선 자주 사용되지 않는 코드가 대부분이다.
> 
> 
> Demand Paging 기법은 실제로 사용될 경우 메모리에 올리기 때문에 많은 프로세스를 메모리에 동시에 올릴 수 있다. 
> 
> Demand Paging 기법에선 무조건 한번은 page fault가 발생한다. (참조될 경우에 메모리에 올리기 때문)
> 
- 실제로 필요할 때 page를 메모리에 올리는 것
    - I/O 양의 감소
        - 한정된 메모리 공간을 조금 더 효율적으로 사용할 수 있기 때문에 Disk 에서 읽어오는 일이 적어짐
    - Memory 사용량 감소
    - 빠른 응답 시간
    - 더 많은 사용자 수용
- Valid / Invalid bit의 사용
    - Invalid 의 의미
        - 사용되지 않는 주소 영역인 경우
        - 페이지가 물리적 메모리에 없는 경우
    - 처음에는 모든 page entry가 invalid로 초기화
    - address translation 시에 Invalid bit이 set되어 있으면
        - “page fault”

## 2. Page Fault

- invalid page를 접근하면 MMU가 trap을 발생시킴 (page fault trap)
- Kernel mode로 들어가서 page fault handler가 invoke됨
- 다음과 같은 순서로 page fault를 처리한다.
    - invalid reference? (eg. bad address, protection violation) → abort process
    - Get an empty frame (없으면 뺏어온다: 다른 페이지가 할당된 frame에 replace)
- 메모리를 획득하면 해당 페이지를 disk에서 momory로 읽어온다
    - disk I/O가 끝나기까지 이 프로세스는 CPU를 preempt 당함 (block)
    - Disk read가 끝나면 page tables entry 기록, valid/invalid bit = “vaild”
    - ready queue에 process를 insert → dispatch later
    - 이 프로세스가 CPU를 잡고 다시 running
    - 아까 중단되었던 instruction을 재개

✔️ **Steps in Handling a Page Fault**

1. 페이지 테이블 엔트리에 접근한다.
2. 접근한 엔트리의 Invalid bit이 invalid이면 trap을 발생시킨다.
3. 커널모드로 변경되어 page가 저장된 하드디스크에 접근한다.
4. page를 비어있는 page frame으로 이동시킨다. 이때 비어있는 page frame이 존재하지 않을경우 다른 페이지가 할당된 frame에 replace한다
5. 새로 할당된 page frame number를 입력하고 invalid bit을 수정한다.
6. trap에 의해 중단되었던 명령어를 다시 수행한다.

![image](https://user-images.githubusercontent.com/56028408/162662911-5e53ed58-7416-496d-8f00-797fe1f456cc.png)

**✔️ Performace of Demand Paging**

- Page Fault Rate  0≤ p ≤ 1.0
    - if p = 0 no page fault
    - if p = 1, every reference is a fault
- Effective Access Time
    - (1 - p) x memory access + P (OS & HW page fault overhead
        
         + [swap page out if needed]
        
         + swap page in
        
         + OS & HW restart overhead)
        

**🌟   실제로 시스템에서  Page Fault Rate를 조사해본 결과 0.09 값이 측정된다. 즉 대부분의 경우는 메모리에서 직접 주소변환이 이뤄진다는 것이다.**

### 2.2 Empty Frame이 없는 경우

**✔️  Page replacement**

- 어떤 frame을 빼앗아올지 결정해야 함
- 곧바로 사용되지 않을 page를 쫓아내는 것이 좋음
- 동일한 페이지가 여러번 메모리에서 쫓겨났다가 다시 들어올 수 있음
- 운영체제의 역할

**✔️  Replacement Algorithm**

- page-fault rate을 최소화하는 것이 목표
- 알고리즘의 평가
    - 주어진 page reference string에 대해 page fault를 얼마나 내는지 조사
- reference string
    - 시간순서에 따라 나열된 page frame (참조된 순서로 나열됨)
    - reference string의 예
        - 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5

**✔️ Page Replacement 흐름**

1. swap out할 victim page를 선점하여 backing store에 swap out시킨다. 이때 변경사항이 있으면 변경된 내용을 저장하고 swap out한다.
2. victim page가 저장되어있던 page table 엔트리의 valid/invalid bit를 invalid 로 수정한다
3. swap out이 완료되면 victim page가 존재하던 frame에 trap을 발생시킨 page를 할당한다.
4. 새롭게 할당된 page가 존재하는 page table 엔트리의 frame number를 수정한다.

**💡 victim page** 

- page replacement에 의해 swap out 되는 페이지를 victim page 라고 한다

![image](https://user-images.githubusercontent.com/56028408/162663269-0ad00235-1654-44ad-aa55-bb1e862cd25e.png)

### 2.3 Optimal Algorithm

> MIN(OPT): 가장 먼 미래에 참조되는 page를 replace
> 

**✔️ Optimal Alogrithm?**

- 미래의 참조를 어떻게 아는가?
    - 미래를 모두 짐작해야하기 때문에 Offline algorithm 실제로 사용되진 않음
- 다른 알고리즘 성능에 대한 upper bound 제공
    - Belady’s optimal algorithm, MIN, OPT 등으로 불림
    

**✔️ Optimal Alogrithm 예시**

![image](https://user-images.githubusercontent.com/56028408/162663068-66b5c86c-af59-4cf2-bd73-7451c519efa3.png)


**[ 가정 ]**

- 빨간색 숫자는 page fault가 발생한 page
- 연보라색 숫자는 메모리로 바로 참조되는 page

**[ 예시 ]**

1. 1,2,3,4번 page의 참조가 발생하여 메모리에 할당한다.
2. 1번과 2번 page가 메모리에서 바로 참조된다.
3. 다음 순서로 5번 page가 참조되어 page fault가 발생한다.
4. 이때 page frame은 모두 꽉 차있는 상태이므로 swap out할 page를 선점한다.
5. 가장 먼 미래에 참조되는 4번 page를 swap out한다. 

### 2.4 FIFO (First In First Out) Algorithm

> 가장 먼저들어온 page를 내쫓는 알고리즘
> 

✔️ **FIFO Anomaly (Belady’s Anomaly)**

- more frames ≠ less page fault
- frame이 많을수록 page fault가 더 자주 일어난다.

**✔️ FIFO (First In First Out) Algorithm 예시**

![image](https://user-images.githubusercontent.com/56028408/162662867-f815886e-bb6b-4e4f-847a-5db4b5d26653.png)


**[가정]**

- 빨간색 숫자는 page fault가 발생한 page
- 연보라색 숫자는 메모리로 바로 참조되는 page

**[예시]**

1. 1,2,3 번 page가 참조되어 page fault가 발생한다.
2. 그 이후 4번 page가 참조되어 가장 먼저 들어온 1번 page가 swap out되고 4번 page가 할당된다.
3. 1번 page가 재참조되어 1번 다음으로 빨리 들어왔던 2번 page를 swap out하고 1번 page를 할당한다.
4. 가장 먼저 할당되었던 page를 swap out하면서 반복

### 2.5 LRU (Least Recently Used) Algorithm

> LRU : 가장 오래 전에 참조된 것을 swap out 시키는 알고리즘
> 
> 
> 가장 오래전에 참조된 알고리즘을 swap out하기 때문에 swap out 되는 page의 인지도는 체크하지 않는다. (여러번 참조되었냐의 여부 확인 안함) 
> 

**✔️  LRU (Least Recently Used) Algorithm 예시**

![image](https://user-images.githubusercontent.com/56028408/162662841-9832b9ff-10e3-4dd8-a32e-8c837bc550d2.png)

**[가정]**

- 빨간색 숫자는 page fault가 발생한 page
- 연보라색 숫자는 메모리로 바로 참조되는 page

**[예시]**

1. 1,2,3,4 번 page가 참조되어 page fault가 발생한다.
2. 1번과 2번 page를 직접 메모리에서 참조한다.
3. 5번 page가 page fault가 발생하여 오래전에 참조되었던 3번 page가 swap out 된다.
4. 가장 오래전에 참조되었던 page를 swap out하면서 반복

### 2.6 LFU (Least Frequently Used) Algorithm

> LFU: 참조 횟수(reference count)가 가장 적은 페이지를 지움
> 

✔️  최저 참조 횟수인 page가 여럿 있는 경우

- LFU 알고리즘 자체에서는 여러 page 중 임의로 선정한다
- 성능 향상을 위해 가장 오래 전에 참조된 page를 지우게 구현할 수도 있다

✔️  장단점

- LRU처럼 직전 참조 시점만 보는 것이 아니라 장기적인 시간 규모를 보기 때문에 page의 인기도를 좀 더 정확히 반영할 수 있음
- 참조 시점의 최근성을 반영하지 못함
- LRU보다 구현이 복잡함

**✔️ LRU와 LFU 알고리즘 예제**

 
![image](https://user-images.githubusercontent.com/56028408/162662834-97cd9c40-0a3b-443e-8a78-c37091d0fc31.png)

**[가정]**

1. page frame은 4칸이 존재함
2. 5번 page를 page fault 발생시켜야 하는 상황

**[예시]**

1. 1번 페이지가 가장 먼저 할당되었고 1번 페이지는 총 4번 참조되었다.
2. 1번 페이지 이후 2번 페이지가 할당되었고 2번 페이지는 총 3번 참조되었다.
3. 2번 페이지 이후 3번 페이지가 할당되었고 3번 페이지는 총 2번 참조되었다.
4. 마지막으로 4번 페이지가 할당되고 4번 페이지는 총 1번 참조되었다.

**[결과]**

- LRU : 가장 오래전에 참조된 1번 page를 삭제함
- LFU : 가장 최근에 할당되었음에도 적게 참조된 4번 page를 삭제함

### 2.7 LRU와 LFU 알고리즘의 구현

![image](https://user-images.githubusercontent.com/56028408/162662824-1638b525-9422-4f5b-a639-f0128a3724ad.png)

**✔️  LRU** 

MRU page에 가까워질 수록 최근에 참조되었다는 것을 나타낸다. LRU 알고리즘은 연결리스트 형태로 구현되어 있으며, 새로운 참조가 발생하면 그 참조가 가장 최근이므로 다른 page와 비교할 것 없이 맨 앞으로 이동한다.

- O(1) **comlexity**

**✔️  LFU**

LFU 알고리즘은 이진 트리로 형성되어 있는 heep을 사용하여 구현할 수 있다. 맨 위 page는 참조횟수가 가장 적은 노드이다. 최상위 노드에 참조횟수가 증가하면 아래 자식노드와 비교하여 참조횟수가 더 큰 노드를 자식노드의 위치와 교환한다.

- O(log n) **comlexity**


# 작 성 중 ..

## **Reference**

---

이화여자대학교 반효경 교수님 운영체제 강의


