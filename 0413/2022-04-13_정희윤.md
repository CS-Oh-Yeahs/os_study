## Demand Paging

- 요청이 있으면 페이지 테이블을 메모리에 적재하는 것
- 효과
    - I/O 양의 감소
    - 물리적 메모리 사용량 감소
    - 빠른 응답 시간
    - 더 많은 사용자 수용
- Valid/Invalid bit 사용
    - Invalid의 의미
        - 페이지가 물리적 메모리에 없고 디스크의 swap공간에 있는 경우 페이지 테이블에서 Invalid로 표시된다.
        - 프로그램을 구성하는 페이지 중 사용되지 않는 페이지에 대해 Invalid로 표시한다.
    - 처음에는 모든 페이지 엔트리가 Invalid로 초기화된다.

### Page Fault

- CPU가 주소 변환을 하고자 할 때 해당 페이지가 Invalid일 경우를 의미한다.
- 요청한 페이지가 메모리에 없는 경우 디스크의 swap 영역에서 해당 페이지를 메모리에 적재해야한다. 이는 운영체제가 관여하는 I/O 작업이기 때문에 CPU가 운영체제에게 넘어가게 되고 운영체제는 디스크에서 페이지를 메모리로 옮기는 작업을 처리한다.
- Page Fault trap : CPU가 Invalid page에 접근하게 되면 MMU가 trap을 발생시킨다.
- 커널 모드로 들어가서 page fault handler(코드)가 실행된다.
- 운영체제의 처리 순서
    1. 잘못된 요청은 아닌지 확인한다.
    2. 메모리에 비어있는 프레임이 없고 꽉 차있을 경우 한 페이지를 메모리에서 쫓아내고 프레임을 확보한다.
    3. 디스크에서 메모리로 페이지를 옮긴다. 
    ⇒ 해당 작업은 매우 느린 작업이므로 파일 입출력 때처럼 CPU를 프로세스로부터 빼앗아서 프로세스를 봉쇄상태로 만든다. 대신 곧바로 CPU를 사용할 수 있는 프로세스에게 CPU의 제어권을 넘긴다.
    4. 디스크 컨트롤러에 해당 페이지를 메모리로 읽어오는 작업을 시킨다.
    5. 디스크 I/O가 끝나면 운영체제가 CPU를 넘겨 받고, 페이지 테이블에서 해당 엔트리를 Valid로 바꾼다.
    6. CPU를 프로세스로 다시 넘겨주어 CPU는 해당 프로세스의 Invalid → valid로 바뀐 엔트리의 페이지를 물리적 메모리 주소로 변환한다.
- 빈 프레임이 없는 경우
    - Page Replacement
        - OS가 어떤 프레임을 쫓아낼지 결정하는 것
        - 곧바로 사용되지 않을 페이지를 쫓아내는 것이 좋다.
        - 동일한 페이지가 여러번 메모리에서 쫓겨났다가 다시 돌아올 수 있다.
    - Replacement Algorithm
        - page-fault rate을 최소화하는 것이 목표
        - 알고리즘의 평가
            - 주어진 page reference string에 대해 page fault를 얼마나 내는지 조사해야 한다.
        - reference string의 예 - 페이지들이 참조되는 순서를 나열
            - 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5

## Page Replacement Algorithms

### Offline Optimal Algorithm(Belady’s optimal algorithm, MIN, OPT)

- 가장 먼 미래에 참조될 페이지를 미리 알고 있어서 이를 당장 메모리에 올라가야 하는 페이지와 대체하는 알고리즘
- 아무리 좋은 알고리즘을 만들어도 Optimal Algorithm보다 좋을 수는 없다. ⇒ 다른 알고리즘의 성능에 대한 upper bound(상한선)를 제공한다.

### FIFO (First In First Out) Algorithm

- 메모리에 먼저 들어온 페이지를 먼저 쫓아내는 알고리즘
- FIFO Anomaly(Belady’s Anomaly)
    - 메모리 프레임을 늘렸다고해서 page fault가 더 적게 발생하는 것이 아닌 아이러니

### LRU(Least Recently Used) Algorithm

- 가장 오래 전에 사용된 페이지를 쫓아내는 방식
- 가장 최근에 참조된 페이지가 다시 참조될 가능성이 높다는 가정 하에 작동한다.
- 구현
    - 페이지를 연결 리스트 형태로 가장 오래 전에 참조된 페이지부터 가장 최근에 참조된 페이지 순으로 줄세운다.
    - 어떤 페이지가 추가될 때마다 링크드 리스트에 참조 순서를 해당 페이지를 고려하여 추가해놓는다.
    - O(1)의 시간 복잡도를 갖는다.

### LFU(Least Frequently Used) Algorithm

- 참조 횟수(reference count)가 가장 적은 페이지를 메모리에서 가장 먼저 쫓아내는 방식
- 최저 참조 횟수인 페이지가 여러 개 있는 경우
    - 여러 개 페이지 중에 임의로 하나를 선택한다.
    - 성능을 향상시키고자 할 경우 마지막 참조 시점이 더 오래된 페이지를 쫓아내도록 구현할 수도 있다.
- 문제점
    - 알고리즘에 의해 메모리에서 삭제된 참조 횟수가 적은 페이지가 사실은 이제 막 여러 번 참조되기 시작하는 페이지일 수가 있다.
- 구현
    - 페이지들을 가장 참조 횟수가 적은 페이지가 맨 위, 밑으로 내려갈 수록 참조 횟수가 많은 페이지로 나열해놓는다.
    - 쫓아낼 때는 참조 횟수가 가장 적은 페이지 순으로 쫓아낸다.
    - 힙을 통해 구현할 경우 O(log n)의 시간복잡도를 갖는다.

## 다양한 캐싱 환경

### 캐싱이란?

- 한정된 빠른 공간(=캐쉬)에 데이터를 저장해두었다가 이후 같은 데이터에 대한 요청이 왔을 때 느린 저장장치를 거치지 않고 캐쉬로부터 바로 데이터를 출력하는 방식
- 페이징 시스템 이외에도 cache memory, buffer caching, web caching 등 다양한 분야에서 사용된다.
- cache memory : CPU에서 메모리를 접근할 때 CPU와 main memory 사이에 cache memory 라는 것이 있다. 그래서 메인 메모리에 접근할 때 캐쉬 메모리에 먼저 접근하여 원하는 데이터가 있는지 확인한다.
- web caching : 웹페이지에 대한 요청을 하면 웹 서버에 해당 페이지를 요청해서 브라우저에 표시하게 되는데 동일한 url에 대해 반복적으로 요청할 경우 웹 서버에서 해당 페이지를 읽어오는 것이 시간이 오래 걸리기 때문에 해당 페이지를 임시로 caching해두었다가 출력해준다.
- 캐쉬 운영의 시간 제약
    - Buffer Caching이나 Web Caching의 경우에는 O(1)와 O(log N) 정도까지 허용한다.
- 페이징 시스템의 경우, page fault인 경우에만 OS가 관여한다. 페이지가 이미 메모리에 존재하는 경우 참조시각 등의 정보를 OS가 알 수 없다. 따라서 앞에서 설명한 LRU와 LFU 같은 알고리즘은 페이징 시스템에서 사용될 수 없다.

### Clock Algorithm(=Second Chance Algorithm, NRU-Not Recently Used)

- 페이징 시스템에서 일반적으로 사용하는 알고리즘
- reference bit를 사용해서 교체 대상 페이지를 선정한다. (시계처럼 원형으로 생겼다.)
- reference bit가 0인 것을 찾을 때까지 포인터를 하나씩 앞으로 이동한다. 1이면 0으로 바꾸면서 이동하다가 0인 reference bit을 찾으면 그 페이지를 교체한다. 한 바퀴 되돌아와서도 0이면 그 때에는 그 페이지를 메모리에서 쫓아낸다.
- 개선된 clock algorithm
    - reference bit와 modified bit(dirty bit)을 함께 사용하여 페이지에 대한 작업이 read가 아닌 write일 때에 대해서도 표시한다.
    - reference bit가 1이면 최근에 참조된 페이지임을 의미하고, modified bit이 1이면 최근에 데이터가 변경된 페이지임을 의미한다.
    - reference bit가 0인 페이지를 메모리에서 쫓아낼 때, modified bit가 1이면 해당 페이지에 대해 수정이 일어났다는 의미이므로 이러한 내용을 반영한 페이지를 backing store(swap area)에 저장한 뒤, 메모리에서 쫓아낸다.
    - 이 방식의 경우 절차 및 비용이 더 커지므로 페이지를 메모리에서 쫓아낼 때, 두 개의 bit를 모두 참조하여 reference bit가 0인 페이지 중에 modified bit도 0인 메모리를 최우선적으로 쫓아내면 오버헤드를 줄일 수 있다.

### Page Frame의 할당

- page fault를 최소화하고 시스템의 효율적인 운영을 위해 각 프로세스에 얼마만큼의 page frame을 할당해야 하는가? 에 대한 문제가 발생한다.
- 필요성
    - 메모리 참조 명령어를 수행할 때, 명령어와 데이터 등의 다양한 내용을 담고있는 여러 페이지가 동시에 참조된다. 이로 인해 명령어 수행을 위해서는 최소한은 꼭 할당되어야 하는 프레임의 수가 있다.
    - 반복문을 구성하는 페이지들은 한꺼번에 할당되는 것이 유리하다. 최소한의 allocation이 없으면 매 loop마다 page fault가 발생할 수 있기 때문이다.
- 방법
    - Equal Allocation : 모든 프로세스에 똑같은 개수를 할당하는 것
    - Proportional Allocation : 프로세스 크기에 비례하여 할당하는 것
    - Priority Allocation : 프로세스의 CPU 우선순위에 따라 다르게 할당하는 것

## Global Replacement VS Local Replacement

### Global Replacement

- 프레임 대체 시, 다른 프로세스에 할당된 프레임을 빼앗아 올 수 있는 방법
- 프로세스별 할당량을 조절하는 하나의 방법으로, FIFO, LRU, LFU 등의 알고리즘을 global replacement로 사용 시에 해당된다.
- Working Set, PFF 알고리즘을 사용한다.

### Local Replacement

- 프레임 대체 시, 자신에게 할당된 프레임 내에서만 replacement가 일어나는 방법
- FIFO, LRU, LFU 등의 알고리즘을 프로세스 별로 운영 시에 해당된다.

## Thrashing

- 전체 프로세스 상에서 page fault가 굉장히 빈번하게 발생하는 현상
- 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당 받지 못한 경우 발생한다.
- 이로 인해 page fault 비율이 매우 높아지면서 cpu 활용도가 낮아진다.
- OS는 MPD(Multiprogramming degree)를 높여야 한다고 판단하여 또 다른 프로세스가 시스템에 추가되면서 프로세스 당 할당된 프레임 수가 더욱 감소하게 되고 프로세스는 페이지의 swap in/out 으로 매우 바쁜 상태가 된다. 반면 CPU는 할 일이 없어지게 되어 한가한 상태가 된다.
- 이를 막기 위해 멀티프로그래밍의 정도를 조절해야 한다. (동시에 메모리에 올라가있는 프로세스의 수를 조절해야한다.)

### Working-Set Model

- locality of reference
    - 프로세스는 특정 시간 동안 일정 장소만을 집중적으로 참조하게 된다.
    예) for loop를 실행하는 동안 해당 구문을 담고있는 페이지들만을 집중적으로 참조한다.
    - 특정 시간에 집중적으로 참조되는 해당 페이지들의 집합을 locality set이라고 한다.
- working-set model에서는 위의 locality set개념을 working set이라고 정의한다.
locality에 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합을 working set이라고 정의한다.
- 이 모델에서는 적어도 working set 전체가 메모리에 동시에 올라와 있어야 하고, 그렇지 못할 경우 모든 프레임을 반납한 후 swap out시킨다.
- 위의 방식을 통해 thrashing 현상을 방지하고 멀티프로그래밍의 정도를 조절한다.

### Working-Set Algorithm

- working-set의 결정
    - 과거에 프로세스에서 델타시간동안 참조된 페이지들을 알아낸다.
    - 해당 페이즈들의 집합을 윈도우라고 하고, 이 집합의 크기는 변화한다.
    - working set에 속한 페이지들은 메모리에 유지하고 속하지 않은 것은 메모리에서 버린다.

### PFF(Page-Fault Frequency) Scheme

- 또 하나의 멀티프로그래밍의 정도를 조절하며 thrashing 현상을 방지하는 방법이다.
- 직접 프로세스의 page fault 비율을 참고하며 해당 비율을 기준으로 프로세스에 메모리를 할당하는 의사결정을 행한다.
- page fault 비율에 상한값과 하한값을 둔다.
    - 해당 비율이 상한값을 넘으면 프레임을 더 할당한다.
    - 해당 비율이 하한값 이하이면 할당 프레임 수를 줄인다.
- 빈 프레임이 없으면 일부 프로세스를 swap out한다.

### Page Size의 결정

- 페이지 사이즈를 감소시킬 경우
    - 페이지 수가 증가된다.
    - 페이지 테이블 크기가 증가된다.
    - Internal fragmentation이 감소된다.
    - disk transfer 의 효율성이 감소된다.
    ⇒ 디스크는 seek를 해야하는데 여기에 시간이 오래 소요된다. 그래서 페이지의 크기가 클수록 해당 시간이 덜 소요되므로 효율성이 증가될 수 있다.
        - seek/rotation vs transfer
    - 필요한 정보만 메모리에 올라오기 때문에 메모리를 더욱 효율적으로 이용할 수 있게 된다.
    페이지 크기가 크게 되면 page fault가 일어났을 때
        - locality 활용 측면에서는 좋지 않다.

⇒ 최근에는 페이지 사이즈를 증가시키고 있다.
