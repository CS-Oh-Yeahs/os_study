# Virtual Memory
### 📂 Demand Paging

- **페이지가 요청이 되었을 때 페이지를 메모리에 올린다**
- 빈번하게 사용하는 필요한 페이지만 메모리에 올리기 때문에
    - I/O 양의 감소
    - 메모리 사용량 감소
    - 빠른 응답 시간
    - 더 많은 사용자 수용
- **Valid/Invalid Bit의 사용 및 Page Fault**
    - 프로그램 최초 실행 시에는 모든 엔트리가 Invalid로 초기화
    - 주소 변환 하려는 페이지가 Invalid일 경우 MMU가 **Page Fault 발생시킴 (일종의 소프트웨어 인터럽트)**
    - **CPU는 운영체제에게 넘어가고 운영체제가 page fault handler를 invoke**
        - 불법적 접근일 경우 abort
        - 빈 프레임을 얻어냄 (빈 프레임이 없을 경우 target을 정해서 쫓아냄)
    - 해당 페이지를 disk에서 메모리로 읽어옴 *(disk IO 작업 느리므로 끝나기까지 프로세스는 CPU를 preempt 당함 - block)*
    - disk read 끝나면 page table entry에 valid bit 기록
    - ready queue에 process insert *(dispatch later)*
    
    🚨 **page fault의 비율에 의해 메모리 접근 시간 커짐**
    

### 📂 Page Replacement

👉 Free frame이 없는 경우 어떤 frame을 빼앗아올지 결정하는 것

- 곧바로 사용되지 않을 page를 쫓아내는 것이 효율적
- Page Fault Rate가 낮아지도록 하는 Replacement Algorithm을 추구
- 디스크에서 메모리로 올라온 이후 내용이 변경된 경우  쫓아낼 때 변경된 내용을 메모리에서 backing store에 저장해줘야함 ↔ 변경 사항이 없을 경우 그냥 메모리에서 지우기만 하면 됨

**1️⃣ Optimal Algorithm (=Belady’s optimal algorithm, MIN, OPT)**

- 가장 먼 미래에 참조되는 page를 replace
- offline algorithm - 미래의 참조될 page reference string을 알고 있다고 가정
- 실제 시스템에서 사용할 수는 없으나, **실제 시스템에 사용하는 알고리즘의 성능에 대한 upper bound 제공**

2️⃣ **FIFO (First In First Out) Algorithm**

- 가장 먼저 들어온 것을 먼저 내쫓음
- FIFO Anomaly (Belady’s Anomaly) more frames ⇒ less page faults
    - 메모리 프레임 개수를 늘리면 성능이 좋아져야 할 것 같지만 오히려 page faults 가 더 발생

3️⃣ **LRU (Least Recently Used) Algorithm**

- 가장 오래 전에 참조된 것을 내쫓음
    - 들어온 기준이 아니고 들어온 이후 (들어온 시점 포함) 사용된 시점 기준

4️⃣ **LFU (Least Frequently Used) Algorithm**

- 참조 횟수가 가장 적은 페이지를 지움
    - 최저 참조 횟수가 여럿 있는 경우 여러 페이지 중 임의로 선정 or 성능 향상을 위해 가장 오래 전에 참조한 페이지를 지우게 구현

### 📂 LRU vs LFU

- **LRU**
    - 마지막 참조 시점만 보기 때문에 이전에 어떤 기록을 갖고 있는지 고려하지 않음
    - 참조 시간 순서에 따라서 한 줄 세우기 *(OS가 링크드 리스트 형태로 관리)*
        - 만약 어떤 페이지가 메모리에 들어오거나 재참조되면 가장 아래 쪽으로 이동시키며, replacement 시에는 가장 위에 있는 페이지를 쫓아냄
    - **O(1) complexity**
        - 무조건 가장 위에 있는 페이지 replace
        - 쫓아내기 위해서 **비교가 필요 없음**
        - cf) 만약 타임스탬프를 저장해놓고 비교한다면 O(n)이 걸릴 것 → 비효율적

- **LFU**
    - 이제 막 참조가 시작되는 상황일 수 있는데 쫓아낼 가능성 존재
    - 한 줄 세우기 할 경우 *(가장 참조횟수가 적은 페이지가 가장 위, 가장 참조횟수가 많은 페이지가 가장 아래)*
        - 참조횟수가 1이 늘어났다고 해서 가장 참조횟수가 많은 것이라고 판단할 수는 없으므로, **비교를 통해서** 어디까지 내려갈지 정해야함
        - O(n) complexity
    - heap *(자식이 2개씩 있는 complete binary tree 구조, min heap)* 이라는 data structure를 이용
        - 참조횟수 하나 늘어났을 때 직계 자식 둘과 비교 후 자식보다 참조횟수가 많을 경우 자리 바꾸기
        - 어디까지 자리를 바꾸며 내려갈 수 있는지 여러 번 비교
        - 루트에 있는 페이지를 replace 후 힙 재구성
        - O(logn) complexity *(complete binary tree의 높이는 logn)*

### 📂 다양한 캐싱 환경

- **캐싱 기법**
    - **한정된 빠른 공간(캐시)**에 요청된 데이터를 저장해 두었다가 후속 요청 시 캐시로부터 직접 서비스하는 방식
    - 한정된 빠른 공간 - 물리적 메모리 vs 느린 저장공간 - 디스크 backing store
    - paging system, cache memory, buffer caching, web caching

- Buffer Caching이나 Web Caching의 경우
    - O(1) 에서 O(logn)까지 허용
- Paging System
    - LRF, LFU 가능한가? 운영체제가 가장 오래전에 쓰인/참조횟수가 가장 적은 페이지를  알 수 있는가? **알 수 없다 🚨**
    - page fault가 나서 CPU 제어권이 운영체제로 넘어온 경우 외에 페이지가 이미 존재하는 경우에는 CPU 제어권이 운영체제에 있지 않기 때문에 알 수 없음

### 📂 Clock Algorithm

- **= Second chance algorithm, NUR(Not Used Recently), NRU(Not Recetly Used)**
    - LRU의 근사 알고리즘
    - 최근에 사용되지 않은 페이지를 쫓아냄 *(cf. LRU처럼 가장 오래전에 사용된 페이지는 OS 입장에서 알 수 없음)*
- Reference Bit
    - 최근에 참조된 페이지를 표시
    - 이미 메모리에 존재하는 페이지에 대해서 하드웨어가 세팅해주는 것 ⭕ 운영체제가 하는 일 ❌
    - 운영체제는 메모리에 존재하는 페이지를 순차적으로 탐색하며 Reference Bit이 1인 페이지는 0으로 변경
    - Reference Bit이 0인 것을 발견한 경우 해당 페이지를 replace
    - Reference Bit이 1 → 0 으로 변경된 페이지의 경우 한 바퀴 되돌아 와서도 0 이면 replace 당할 수 있음
- Modified Bit
    - 최근에 변경된 페이지를 표시
    - 만약 Modified Bit이 0이라면 backing store에서 물리적 메모리로 올라온 이후로 수정이 이루어지지 않았음을 의미
    - Modified Bit 이 1인 페이지를 쫓아내려면 변경 내역을 디스크에 써주고 쫓아내야 하므로 시간이 더 걸림

### 📂 Allocation Scheme

- Equal Allocation → 모든 프로세스에 똑같은 개수 할당
- Proportional Allocation → 프로세스 크기에 비례하여 할당
- Priority Allocation → 프로세스의 우선순위에 따라 다르게 할당

### 📂 Global vs Local Replacement

- **Global Replacement**
    - 굳이 프로세스 별 페이지를 **미리 할당하지 않고 replace 시 다른 프로세스에 할당된 frame을 빼앗아 올 수 있음**
    - 프로세스  별 할당량을 조절하는 또 다른 방법
    - FIFO, LRU, LFU을 global replacement로 사용 시에 해당
    - **Working set, PFF**
- **Local Replacement**
    - 자신에게 **할당된 프레임 내에서만 replacement가 이루어짐**
    - FIFO, LRU, LFU 등의 알고리즘을 프로세스 별로 운영 시

### 📂 Thrashing

- 프로세스의 원활한 수행에 필요한 최소한의 page frame 수를 할당 받지 못한 경우 발생
    - page fault rate이 매우 높아짐
    - CPU utilization이 낮아짐
    - **Multi-Programming Degree가 너무 높아질 경우 프로세스 당 할당된 frame의 수가 점차 감*소**
    - 프로세스는 page의 swap in/out 으로 매우 바쁨
    - 대부분의 시간에 CPU는 한가하여 low throughput
- 해결) Multi-Programming Degree 조절 → Working-Set Model, PPF

### 📂 Working-Set Model

- **Locality of reference**
    - 프로세스가 특정 시간 동안 일정 장소만을 집중적으로 참조하는 성질
    - 집중적으로 참조되는 해당 page들의 집합 locality set

- **Working set model**
    - **locality에 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 일련의 page들의 집합 working set**
    - working set 모델에서는 working set 전체 메모리가 올라와 있어야 수행 or 모든 프레임을 반납 후 swap out
    - 과거를 통해서 window size에 따라 working set을 추정
    - working set은 시점에 따라 계속해서 바뀜
    - 일종의 참조된 페이지를 일정 시간 *(window size)* 동안만 유지하고 버리는 형식

working set 델타 값이 너무 작을 경우 → locality set을 모두 수용하지 못할 수 있음

working set 델타 값이 너무 크면 → 여러 규모의 locality set 수용

### 📂 PFF(Page-Fault Frequency) scheme

- 직접 page fault rate를 보고 판단
- page-fault rate의 상한값과 하한값을 두고
    - **상한값을 넘으면 frame을 더 할당**
    - **하한값 이하이면 할당 frame 수를 줄임**
- 빈 프레임이 없으면 일부 프로세스를 swap out

### 📂 page size의 결정

- page size를 감소시키면
    - 페이지 수 증가
    - 페이지 테이블 크기 증가
    - 내부 단편화 감소
    - disk transfer의 효율성 감소
    - 필요한 정보만 메모리에 올라와 메모리 이용이 효율적 *(페이지가 크면 페이지에서 아주 적은 정보만 필요해도 page fault 발생 시 페이지 전체를 올려야 하므로)* ↔ locality 활용 측면에서는 좋지 않음
- 최근에는 페이지 크기를 키우는 추세
